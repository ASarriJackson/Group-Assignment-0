{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflection on Financial Data Sets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this final section, we reflect on our collective findings from our four topics of research: \n",
    "* World Bank's Loan Programs\n",
    "* Bank Loan Prediction\n",
    "* Bank Churning Analysis \n",
    "* Customer interest in Long-Term Savings Accounts\n",
    "\n",
    "We have noticed that most financial data sets are similar in the data collected. Demographic Data was used across all datasets to profile customers or countries to see if demographics play a role whether in predicting if a customer will churn or if certain demographics are more likely to be accepted for a loan. Arguably the most imformative was transactional data which is captured heavvily in customer interactions, financial transactions and country repayment plans. The world bank prodominantly analyses off of country repayment histories in order to determain future credit agreements. \n",
    "\n",
    "The datasets used in our final report were all sourced from public data repositries. We primarily used Kaggle because we wanted already established code analysing these datasets. We were then able to build upon these examples to develop a rigerous understanfing of our individual topics. Additionally, the World Bank also offers great recources if you seek transactional history from various countries. \n",
    "\n",
    "For our project, we chose Python as our primary tool for analysis. This was because of our collective prior experience and familiarity with packages specially designed for exploratory data analyses. In particular, we used libraries such as Pandas, NumPy and scikit-learn, which are ideal for handling large datasets and creating informative visualisations. In order to share and access each others code we used a github repository, which streamlined our workflow by allowing simultanious contributions to the project. \n",
    "\n",
    "We focused on resources to develop forecast and predictive models that primarily benefit bankiing decisions through understanding customer behaviours. There were some recources we saw that weren't relevant to our topic but are used in other areaas of financial analysis. For example some datasets are collected to develop fraud detection, which would allow banks to identify suspicious activities and assess risks.\n",
    "\n",
    "For our basic analysis we used EDA techniques and plotted distribution and correlation graphs to conduct basic analysis on usefulness of variables. Another general tool we used was data cleaning to avoid missing and erroneous values. For further analysis on a variety of financial datasets we can apply machine learning techniques such as classification and regression.\n",
    "\n",
    "\n",
    "\n",
    "After much deliberation, we decided to further investigate Customer Churning "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
